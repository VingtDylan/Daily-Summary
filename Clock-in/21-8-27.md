<img src = "https://img.shields.io/badge/-Info%20%26%20Date-blueviolet" align="left">

<font color=gray size=3>姓名</font>:  陈勇虎

<font color=gray size=3>日期</font>: 2021年8月27日 星期五

<img src = "https://img.shields.io/badge/-Plan-blueviolet" align="left">

- [ ] 编译deepmatching[1]官方代码并测试
- [ ] 学习点云拼接实例
- [ ] 参考《视觉SLAM十四讲》学习ORB特征点

<img src = "https://img.shields.io/badge/-Do-blueviolet" align="left">

1. 编译deepmatching官方代码并测试
2. 学习点云拼接实例
3. 参考《视觉SLAM十四讲》学习ORB特征点

<img src = "https://img.shields.io/badge/-Check-blueviolet" align="left">

1. 同步链接到[github链接][https://github.com/VingtDylan/Daily-Summary/tree/main/code/21-8-27-deepmatching]，显示效果如下所示。

   <img src = "images\deepmatching.png" align="center" style="width:70%">
   
2. 学习拼接点云的示例

3. **FAST**关键点属于计算特别快的特征点，没有描述子。

   **ORB**特征改进了FAST检测子不具有方向性的问题，并次啊用速度较快的二进制描述子**BRIEF**，使得整个图像特征的提取过程大大加快。**ORB**是在目前的SLAM方案中，质量与性能之间比较好的折中。

   ORB特征亦由关键点和描述子组成。它的关键点称为”Oriented FAST“，是一种改进的FAST角点。它的描述子称为BRIEF，因此提取ORB特征分为两个步骤：

   1. FAST角点提取：找出图像的角点，此外，ORB还会计算特征点的主方向，以增加旋转不变性。
   2. BRIEF描述子：对得到的FAST特征点的周围区域进行描述。

   FAST是一种角点，用于检测局部像素灰度变化明显的地方，它的思想是：如果一个像素与它邻域的像素差别较大（过亮或过暗），那他更可能是角点。相比于其他的角点检测算法，FAST只需比较像素亮度的大小，他的检测过程如下：

   1. 在图像中选取像素点 $p$, 假设其亮度为 $I_p$
   2. 设置一个阈值 $T$
   3. 以像素 $p$为中心，选取半径为3的圆上的16个像素点
   4. 假设选取的圆上，由连续的 N 个点的亮度大于 $I_p + T$ 或小于 $I_p - T$，那么像素点 $p$ 可以被认为是特征点，通常 $N$ 取12，即FAST-12。
   5. 循环以上四步，对每一个像素点执行相同的操作。

   <img src = "/images\FAST.png" align="center" style="width:65%">

   在FAST-12算法中，可以添加一项预测试操作，以快速排除绝大多数不是角点的元素。即对于每个像素，直接检测其邻域圆上的第1，5，9，13个像素的亮度。只有当这四个像素中有三个同时大于 $I_p+T$ 或小于 $I_p - T$ 时，当前像素才有可能是一个角点，否则应该直接排除，这个操作大大加快了角点检测。

   原始的FAST角点经常出现”扎堆“的现象。所以在第一遍检测之后，还需要用非极大值抑制（Non-maximal suppression），在一定区域内仅保留响应极大值的角点，避免角点集中的问题。

   FAST特征点的计算仅仅是比较像素间亮度的差异，速度很快但仍有一些问题。

   首先，FAST特征点数量很大且不确定，而往往希望对图像提取固定数量的特征。因此，在ORB中，对原始的FAST算法进行了改进。可以指定最重要提取的角点数量N，对原始FAST角点分别计算Harris响应值，然后选取前N个具有最大响应值的角点，作为最终的角点集合。其次，FAST角点不具有方向性，而且由于固定选取半径为 3 的圆，存在尺度问题。对此 ORB 添加了对尺度和旋转的描述。尺度不变性由构建图像金字塔，并在金字塔的每一层上检测角点来实现。而特征的旋转是由灰度质心法（Intensity Centroid）实现。

   质心是指以图像块灰度值作为权重的中心，其操作步骤具体如下：

   1. 在一个小的图像块B中，定义图像块的矩为：
      $$
      m_{pq} = \sum_{x,y\in B}x^py^qI(x,y),  \quad p, q\in\{0, 1\}
      $$

   2. 通过矩可以找到图像块的质心：
      $$
      C = (\frac{m_{10}}{m_{00}}, \frac{m_{01}}{m_{00}})
      $$

   3. 连接图像块的几何中心 O 与质心 C，得到一个方向向量 $\vec{OC}$,于是特征点的方向可以定义为：
      $$
      \theta = \arctan(m_{01}/m_{10})
      $$

   通过以上方法，FAST角点便具有了尺度和旋转的描述，大大提升了它们在不同图像之间表述的鲁棒性。

   BRIEF 是一种二进制描述子，它的描述向量由许多个 0 和 1 组成，这里的 0 和 1 编码了关键点附近两个像素（比如说 p 和 q）的大小关系：如果 p 比 q 大，则取1，反之就取 0。如果我们取了 128 个这样的 p, q，最后就得到 128 维由 0，1 组成的向量。在作者原始的论文中给出了若干种挑选 p , q 的方法，大体上都是按照某种概率分布，随机地挑选 p 和 q 的位置。BRIEF 使用了随机选点的比较，速度非常快，而且由于使用了二进制表达，存储起来也十分方便，适用于实时的图像匹配。原始的BRIEF 描述子不具有旋转不变性的，因此在图像发生旋转时容易丢失。而 ORB 在 FAST 特征点提取阶段计算了关键点的方向，所以可以利用方向信息，计算了旋转之后的**Steer BRIEF**特征，使 ORB 的描述子具有较好的旋转不变性。


<img src = "https://img.shields.io/badge/-Action-blueviolet" align="left">

1.  继续调研光流法动态感知领域的应用算法和光流估计算法

<img src = "https://img.shields.io/badge/-Reference-blueviolet" align = "left">

1. Revaud, J., Weinzaepfel, P., Harchaoui, Z. *et al.* DeepMatching: Hierarchical Deformable Dense Matching. *Int J Comput Vis* 120, 300–323 (2016). https://doi.org/10.1007/s11263-016-0908-3

















