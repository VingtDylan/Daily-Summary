<img src = "https://img.shields.io/badge/-Info%20%26%20Date-blueviolet" align="left">

<font color=gray size=3>姓名</font>:  陈勇虎

<font color=gray size=3>日期</font>: 2021年8月19日 星期四

<img src = "https://img.shields.io/badge/-Plan-blueviolet" align="left">

- [ ] 了解opencv中部分库函数，对对极约束作简单实现和验证
- [ ] 学习单应约束等相关知识
- [ ] 泛读《Motion Segmentation Via a Sparsity Constraint》

<img src = "https://img.shields.io/badge/-Do-blueviolet" align="left">

1. 调用opencv库函数学习对极约束
2. 参考博客[1]和《视觉SLAM十四讲》学习单应约束(矩阵)[2]
3. 泛读论文《Motion Segmentation Via a Sparsity Constraint》[3]

<img src = "https://img.shields.io/badge/-Check-blueviolet" align="left">

1. ORB查找关键点和描述子，使用cv2.findFundamentalMat计算本质矩阵。[github同步链接](https://github.com/VingtDylan/Daily-Summary/tree/main/code/2020-8-19-Epipolar_Geometry)

   <img src = "images\Epipolar_Geometry.png" align="center" style="width:80%">

2. 对极约束和场景结构无关，只能给出点对应的必要条件，单应则要求场景的点都在同一个平面上，因此单应矩阵H能求出另一副图像上像点的确切位置。

   <img src = "images\homography.png" align="center" style="width: 40%">

   如果使用同一个相机在不同位姿下拍摄同一个平面，平面$\pi$在两个相机下成像，设平面$\pi$在第一相机坐标系下的单位法向量为N，其到第一个相机中心的距离为d,则平面$\pi$可以表示为：
   $$
   N^Tx_1=d
   $$
   即:
   $$
   \frac{1}{d}N^TX_1=1,\forall X_1\in\pi
   $$
   其中,$X_1$是三维点$P$在第一相机坐标系下的坐标，其在第二个相机坐标系下的坐标为$X_2$，则
   $$
   X_2=RX_1+T
   $$
   结合上面式子，则有:
   $$
   X_2=RX_1+T\frac{1}{d}N^TX_1=(R+T\frac{1}{d}N^T)X_1=H^{'}X_1
   $$
   得单应矩阵:
   $$
   H^{'}=R+T\frac{1}{d}N^T
   $$
   设$x_1,x_2$为$P$在两图像的像点坐标，
   $$
   x_1=KX_1,x_2=KX_2
   $$
   记$K$是相机的内参数，带入单应变换公式中，
   $$
   K^{-1}x_2=HK^{-1}x_1\Longrightarrow x_2=KH^{'}K^{-1}x_1=K(R+T\frac{1}{d}N^T)K^{-1}x_1
   $$
   从而，同一平面得到的两个图像间的单应矩阵H为:
   $$
   H=K(R+T\frac{1}{d}N^T)K^{-1}
   $$

3. 当观测目标退化成平面或者只存在纯旋转运动时，对极关系建立的约束会发生退化现象，针对这种情况,该论文使用单应关系进行匹配建模。

   该论文提出的方法也是affinity-based的方法，与《Rigid Motion Segmentation using Randomized Voting》相比，不需要预设运动的数量，也更贴合实际的情况。

   对于运动数量的计算，论文中采用下式作为损失函数，使得该式最小化的$\hat{c}\in{1,2,...,C}$即为运动数量的个数。
   $$
   \mathcal{F}=\sum_{n=1}^{N} \sum_{c=1}^{C} V_{i, j}^{2} /\left(\max \mathbf{V}_{i}\right)^{2}
   $$

<img src = "https://img.shields.io/badge/-Action-blueviolet" align="left">

1.  继续调研光流估计相关论文，以及光流法在动态感知领域的算法
2.  逐步学习多视图几何和相机模型

<img src = "https://img.shields.io/badge/-Reference-blueviolet" align = "left">

1. https://www.cnblogs.com/wangguchangqing/p/8287585.html#autoid-1-0-0
2. 《视觉SLAM十四讲》
3. Lai, Taotao, Hanzi Wang, Yan Yan, Tat-Jun Chin, and Wan-Lei Zhao. 2017. “Motion Segmentation Via a Sparsity Constraint.” *IEEE Transactions on Intelligent Transportation Systems* 18 (4): 973–83. https://doi.org/10.1109/TITS.2016.2596296.



























