# Python深度学习

## Python

### builtin

* **sorted**

  > **sort 与 sorted 区别：**
  >
  > sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。
  >
  > list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。

  **sorted(iterable, cmp=None, key=None, reverse=False)**

  > 参数说明：
  >
  > - iterable -- 可迭代对象。
  > - cmp -- 比较的函数，这个具有两个参数，参数的值都是从可迭代对象中取出，此函数必须遵守的规则为，大于则返回1，小于则返回-1，等于则返回0。
  > - key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。
  > - reverse -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。
  > - out -- 返回重新排列后的列表

---

### Python 标准库

#### glob

glob模块提供了一个函数用于从目录通配符搜索中生成文件列表:

> images = sorted(glob.glob(os.path.join(root, 'image_2/*_10.png')))

---

#### os

TODO



---

## PyTorch

### torch

#### Creation Ops

* **torch.arange**

  **torch.arange(start, end, step=1, out=None) → Tensor**

  返回一个1维张量，长度为 \( floor((end−start)/step) \)。包含从 **start**到 **end**，以 **step** 为步长的一组序列值(默认步长为1)。

  > 参数:
  >
  > - start (float) – 序列的起始点
  > - end (float) – 序列的终止点
  > - step (float) – 相邻点的间隔大小
  > - out (Tensor, optional) – 结果张量

---

#### Indexing, Slicing, Joining, Mutating Ops

* **torch.split**

  **torch.split(tensor, split_size, dim=0)**

  将输入张量分割成相等形状的chunks（如果可分）。 如果沿指定维的张量形状大小不能被 **split_size** 整分， 则最后一个分块会小于其它分块。

  > 参数:
  >
  > - tensor (Tensor) – 待分割张量
  > - split_size (int) – 单个分块的形状大小
  > - dim (int) – 沿着此维进行分割

* **torch.stack**

  **torch.stack(sequence, dim=0)**
  
  沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。
  
  >   参数:
  >
  >   - sequence (Sequence) – 待连接的张量序列
  >   - dim (int) – 插入的维度。必须介于 0 与 待连接的张量序列数之间。

---

#### Math operations

**PointWise Ops**

* **torch.tanh**

  **torch.tanh(input, out=None) → Tensor**

  返回一个新张量，包含输入 **input** 张量每个元素的双曲正切。

  > 参数：
  >
  > - input (Tensor) – 输入张量
  > - out (Tensor, optional) – 输出张量

* 



**Reduction Ops**

* 


---

### torch.Tensor

* **expand(*sizes)**

  返回tensor的一个新视图，单个维度扩大为更大的尺寸。 tensor也可以扩大为更高维，新增加的维度将附在前面。 扩大tensor不需要分配新内存，只是仅仅新建一个tensor的视图，其中通过将`stride`设为0，一维将会扩展位更高维。任何一个一维的在不分配新内存情况下可扩展为任意的数值。

  > **参数：** 
  >
  > - **sizes(torch.Size or int...)**-需要扩展的大小

---

### torch.nn

#### torch.nn.normalization

Norm 归一化层 [链接](https://blog.csdn.net/shanglianlm/article/details/85075706)

> BN，LN，IN，GN从学术化上解释差异：
> BatchNorm：batch方向做归一化，算NHW的均值，对小batchsize效果不好；BN主要缺点是对batchsize的大小比较敏感，由于每次计算均值和方差是在一个batch上，所以如果batchsize太小，则计算的均值、方差不足以代表整个数据分布
> LayerNorm：channel方向做归一化，算CHW的均值，主要对RNN作用明显；
> InstanceNorm：一个channel内做归一化，算H*W的均值，用在风格化迁移；因为在图像风格化中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。
> GroupNorm：将channel方向分group，然后每个group内做归一化，算(C//G)HW的均值；这样与batchsize无关，不受其约束。
> SwitchableNorm是将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。

**nn.GroupNorm**

* **torch.nn.GroupNorm(*num_groups*, *num_channels*, *eps=1e-05*, *affine=True*, *device=None*, *dtype=None*)** [链接](https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html)

> - **num_groups** ([*int*](https://docs.python.org/3/library/functions.html#int)) – number of groups to separate the channels into
> - **num_channels** ([*int*](https://docs.python.org/3/library/functions.html#int)) – number of channels expected in input
> - **eps** – a value added to the denominator for numerical stability. Default: 1e-5
> - **affine** – a boolean value that when set to `True`, this module has learnable per-channel affine parameters initialized to ones (for weights) and zeros (for biases). Default: `True`.

**nn.BatchNorm**

* **torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)**

* **torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)**

  对小批量(mini-batch)3d数据组成的4d输入进行批标准化(Batch Normalization)操作

  $$
  y = \frac{x - mean[x]}{ \sqrt{Var[x]} + \epsilon} * gamma + beta
  $$

  在每一个小批量（mini-batch）数据中，计算输入各个维度的均值和标准差。gamma与beta是可学习的大小为C的参数向量（C为输入大小）

  在训练时，该层计算每次输入的均值与方差，并进行移动平均。移动平均默认的动量值为0.1。

  在验证时，训练求得的均值/方差将用于标准化验证数据

* **torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)**

> num_features： 来自期望输入的特征数，该期望输入的大小为’batch_size x num_features [x width]’
> eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。
> momentum： 动态均值和动态方差所使用的动量。默认为0.1。
> affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。
> track_running_stats：布尔值，当设为true，记录训练过程中的均值和方差；

**nn.InstanceNorm2d** [链接](https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html)

**torch.nn.InstanceNorm2d(*num_features*, *eps=1e-05*, *momentum=0.1*, *affine=False*, *track_running_stats=False*, *device=None*, *dtype=None*)**

> - **num_features** – C from an expected input of size (N,C,H,W)
> - **eps** – a value added to the denominator for numerical stability. Default: 1e-5
> - **momentum** – the value used for the running_mean and running_var computation. Default: 0.1
> - **affine** – a boolean value that when set to `True`, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: `False`.
> - **track_running_stats** – a boolean value that when set to `True`, this module tracks the running mean and variance, and when set to `False`, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: `False`

---

### torch.cuda.amp

#### torch.cuda.amp.autocast

开启自动混合精度，[链接](https://zhuanlan.zhihu.com/p/165152789)

**torch.cuda.amp.autocast(enabled=True)**

---

## Numpy







